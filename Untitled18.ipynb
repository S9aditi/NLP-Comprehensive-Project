{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "e185cdfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "6906a0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"Text\":[\"The cat sat on the good mat\",\n",
    "    \"The dog lay on the good rug\",\n",
    "    \"The cat chased the mouse\",\n",
    "    \"Apple is a good, but I prefer Orange products.\",\n",
    "    \"The dog barked at the cat\",\n",
    "    \"cat was drinking the milk\",\n",
    "    \"peter, was playing with dog\",\n",
    "    \"Tesla is going to acquire twitter for $45 billion\",\n",
    "    \"Michael Blooberg founded Blommerg L.P. in 1982\"],\n",
    "    \"label\":[0,1,0,1,1,0,0,1,1]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "6abfc4b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The cat sat on the good mat</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The dog lay on the good rug</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The cat chased the mouse</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Apple is a good, but I prefer Orange products.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The dog barked at the cat</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cat was drinking the milk</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>peter, was playing with dog</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Tesla is going to acquire twitter for $45 billion</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Michael Blooberg founded Blommerg L.P. in 1982</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  label\n",
       "0                        The cat sat on the good mat      0\n",
       "1                        The dog lay on the good rug      1\n",
       "2                           The cat chased the mouse      0\n",
       "3     Apple is a good, but I prefer Orange products.      1\n",
       "4                          The dog barked at the cat      1\n",
       "5                          cat was drinking the milk      0\n",
       "6                        peter, was playing with dog      0\n",
       "7  Tesla is going to acquire twitter for $45 billion      1\n",
       "8     Michael Blooberg founded Blommerg L.P. in 1982      1"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c4e106",
   "metadata": {},
   "source": [
    "### Taking out the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "b44a5716",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Apple is a good, but I prefer Orange products.',\n",
       " 'Michael Blooberg founded Blommerg L.P. in 1982',\n",
       " 'Tesla is going to acquire twitter for $45 billion',\n",
       " 'The cat chased the mouse',\n",
       " 'The cat sat on the good mat',\n",
       " 'The dog barked at the cat',\n",
       " 'The dog lay on the good rug',\n",
       " 'cat was drinking the milk',\n",
       " 'peter, was playing with dog'}"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = set(df[\"Text\"])\n",
    "corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7273bd0",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "8ea0093d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>label</th>\n",
       "      <th>Token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The cat sat on the good mat</td>\n",
       "      <td>0</td>\n",
       "      <td>[The, cat, sat, on, the, good, mat]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The dog lay on the good rug</td>\n",
       "      <td>1</td>\n",
       "      <td>[The, dog, lay, on, the, good, rug]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The cat chased the mouse</td>\n",
       "      <td>0</td>\n",
       "      <td>[The, cat, chased, the, mouse]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Apple is a good, but I prefer Orange products.</td>\n",
       "      <td>1</td>\n",
       "      <td>[Apple, is, a, good,, but, I, prefer, Orange, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The dog barked at the cat</td>\n",
       "      <td>1</td>\n",
       "      <td>[The, dog, barked, at, the, cat]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cat was drinking the milk</td>\n",
       "      <td>0</td>\n",
       "      <td>[cat, was, drinking, the, milk]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>peter, was playing with dog</td>\n",
       "      <td>0</td>\n",
       "      <td>[peter,, was, playing, with, dog]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Tesla is going to acquire twitter for $45 billion</td>\n",
       "      <td>1</td>\n",
       "      <td>[Tesla, is, going, to, acquire, twitter, for, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Michael Blooberg founded Blommerg L.P. in 1982</td>\n",
       "      <td>1</td>\n",
       "      <td>[Michael, Blooberg, founded, Blommerg, L.P., i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  label  \\\n",
       "0                        The cat sat on the good mat      0   \n",
       "1                        The dog lay on the good rug      1   \n",
       "2                           The cat chased the mouse      0   \n",
       "3     Apple is a good, but I prefer Orange products.      1   \n",
       "4                          The dog barked at the cat      1   \n",
       "5                          cat was drinking the milk      0   \n",
       "6                        peter, was playing with dog      0   \n",
       "7  Tesla is going to acquire twitter for $45 billion      1   \n",
       "8     Michael Blooberg founded Blommerg L.P. in 1982      1   \n",
       "\n",
       "                                               Token  \n",
       "0                [The, cat, sat, on, the, good, mat]  \n",
       "1                [The, dog, lay, on, the, good, rug]  \n",
       "2                     [The, cat, chased, the, mouse]  \n",
       "3  [Apple, is, a, good,, but, I, prefer, Orange, ...  \n",
       "4                   [The, dog, barked, at, the, cat]  \n",
       "5                    [cat, was, drinking, the, milk]  \n",
       "6                  [peter,, was, playing, with, dog]  \n",
       "7  [Tesla, is, going, to, acquire, twitter, for, ...  \n",
       "8  [Michael, Blooberg, founded, Blommerg, L.P., i...  "
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenization(text):\n",
    "    return text.split()\n",
    "\n",
    "df[\"Token\"]=df[\"Text\"].apply(tokenization)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a55f0ec",
   "metadata": {},
   "source": [
    "### Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "8281b4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatization(text):\n",
    "    a=[]\n",
    "    nlp=spacy.load(\"en_core_web_md\")\n",
    "    doc=nlp(text)\n",
    "    for token in doc:\n",
    "        if token.is_punct or token.is_stop:\n",
    "            continue\n",
    "        a.append(token.lemma_)\n",
    "    return \" \".join(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "9874049f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>label</th>\n",
       "      <th>Token</th>\n",
       "      <th>lema</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The cat sat on the good mat</td>\n",
       "      <td>0</td>\n",
       "      <td>[The, cat, sat, on, the, good, mat]</td>\n",
       "      <td>cat sit good mat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The dog lay on the good rug</td>\n",
       "      <td>1</td>\n",
       "      <td>[The, dog, lay, on, the, good, rug]</td>\n",
       "      <td>dog lie good rug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The cat chased the mouse</td>\n",
       "      <td>0</td>\n",
       "      <td>[The, cat, chased, the, mouse]</td>\n",
       "      <td>cat chase mouse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Apple is a good, but I prefer Orange products.</td>\n",
       "      <td>1</td>\n",
       "      <td>[Apple, is, a, good,, but, I, prefer, Orange, ...</td>\n",
       "      <td>Apple good prefer Orange product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The dog barked at the cat</td>\n",
       "      <td>1</td>\n",
       "      <td>[The, dog, barked, at, the, cat]</td>\n",
       "      <td>dog bark cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cat was drinking the milk</td>\n",
       "      <td>0</td>\n",
       "      <td>[cat, was, drinking, the, milk]</td>\n",
       "      <td>cat drink milk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>peter, was playing with dog</td>\n",
       "      <td>0</td>\n",
       "      <td>[peter,, was, playing, with, dog]</td>\n",
       "      <td>peter play dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Tesla is going to acquire twitter for $45 billion</td>\n",
       "      <td>1</td>\n",
       "      <td>[Tesla, is, going, to, acquire, twitter, for, ...</td>\n",
       "      <td>Tesla go acquire twitter $ 45 billion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Michael Blooberg founded Blommerg L.P. in 1982</td>\n",
       "      <td>1</td>\n",
       "      <td>[Michael, Blooberg, founded, Blommerg, L.P., i...</td>\n",
       "      <td>Michael Blooberg found Blommerg L.P. 1982</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  label  \\\n",
       "0                        The cat sat on the good mat      0   \n",
       "1                        The dog lay on the good rug      1   \n",
       "2                           The cat chased the mouse      0   \n",
       "3     Apple is a good, but I prefer Orange products.      1   \n",
       "4                          The dog barked at the cat      1   \n",
       "5                          cat was drinking the milk      0   \n",
       "6                        peter, was playing with dog      0   \n",
       "7  Tesla is going to acquire twitter for $45 billion      1   \n",
       "8     Michael Blooberg founded Blommerg L.P. in 1982      1   \n",
       "\n",
       "                                               Token  \\\n",
       "0                [The, cat, sat, on, the, good, mat]   \n",
       "1                [The, dog, lay, on, the, good, rug]   \n",
       "2                     [The, cat, chased, the, mouse]   \n",
       "3  [Apple, is, a, good,, but, I, prefer, Orange, ...   \n",
       "4                   [The, dog, barked, at, the, cat]   \n",
       "5                    [cat, was, drinking, the, milk]   \n",
       "6                  [peter,, was, playing, with, dog]   \n",
       "7  [Tesla, is, going, to, acquire, twitter, for, ...   \n",
       "8  [Michael, Blooberg, founded, Blommerg, L.P., i...   \n",
       "\n",
       "                                        lema  \n",
       "0                           cat sit good mat  \n",
       "1                           dog lie good rug  \n",
       "2                            cat chase mouse  \n",
       "3           Apple good prefer Orange product  \n",
       "4                               dog bark cat  \n",
       "5                             cat drink milk  \n",
       "6                             peter play dog  \n",
       "7      Tesla go acquire twitter $ 45 billion  \n",
       "8  Michael Blooberg found Blommerg L.P. 1982  "
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"lema\"]=df[\"Text\"].apply(lemmatization)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "21e197ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Apple good prefer Orange product',\n",
       " 'Michael Blooberg found Blommerg L.P. 1982',\n",
       " 'Tesla go acquire twitter $ 45 billion',\n",
       " 'cat chase mouse',\n",
       " 'cat drink milk',\n",
       " 'cat sit good mat',\n",
       " 'dog bark cat',\n",
       " 'dog lie good rug',\n",
       " 'peter play dog'}"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatized_corpus=set(df[\"lema\"])\n",
    "lemmatized_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "0c7adf8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>label</th>\n",
       "      <th>Token</th>\n",
       "      <th>lema</th>\n",
       "      <th>lema_token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The cat sat on the good mat</td>\n",
       "      <td>0</td>\n",
       "      <td>[The, cat, sat, on, the, good, mat]</td>\n",
       "      <td>cat sit good mat</td>\n",
       "      <td>[cat, sit, good, mat]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The dog lay on the good rug</td>\n",
       "      <td>1</td>\n",
       "      <td>[The, dog, lay, on, the, good, rug]</td>\n",
       "      <td>dog lie good rug</td>\n",
       "      <td>[dog, lie, good, rug]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The cat chased the mouse</td>\n",
       "      <td>0</td>\n",
       "      <td>[The, cat, chased, the, mouse]</td>\n",
       "      <td>cat chase mouse</td>\n",
       "      <td>[cat, chase, mouse]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Apple is a good, but I prefer Orange products.</td>\n",
       "      <td>1</td>\n",
       "      <td>[Apple, is, a, good,, but, I, prefer, Orange, ...</td>\n",
       "      <td>Apple good prefer Orange product</td>\n",
       "      <td>[Apple, good, prefer, Orange, product]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The dog barked at the cat</td>\n",
       "      <td>1</td>\n",
       "      <td>[The, dog, barked, at, the, cat]</td>\n",
       "      <td>dog bark cat</td>\n",
       "      <td>[dog, bark, cat]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cat was drinking the milk</td>\n",
       "      <td>0</td>\n",
       "      <td>[cat, was, drinking, the, milk]</td>\n",
       "      <td>cat drink milk</td>\n",
       "      <td>[cat, drink, milk]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>peter, was playing with dog</td>\n",
       "      <td>0</td>\n",
       "      <td>[peter,, was, playing, with, dog]</td>\n",
       "      <td>peter play dog</td>\n",
       "      <td>[peter, play, dog]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Tesla is going to acquire twitter for $45 billion</td>\n",
       "      <td>1</td>\n",
       "      <td>[Tesla, is, going, to, acquire, twitter, for, ...</td>\n",
       "      <td>Tesla go acquire twitter $ 45 billion</td>\n",
       "      <td>[Tesla, go, acquire, twitter, $, 45, billion]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Michael Blooberg founded Blommerg L.P. in 1982</td>\n",
       "      <td>1</td>\n",
       "      <td>[Michael, Blooberg, founded, Blommerg, L.P., i...</td>\n",
       "      <td>Michael Blooberg found Blommerg L.P. 1982</td>\n",
       "      <td>[Michael, Blooberg, found, Blommerg, L.P., 1982]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  label  \\\n",
       "0                        The cat sat on the good mat      0   \n",
       "1                        The dog lay on the good rug      1   \n",
       "2                           The cat chased the mouse      0   \n",
       "3     Apple is a good, but I prefer Orange products.      1   \n",
       "4                          The dog barked at the cat      1   \n",
       "5                          cat was drinking the milk      0   \n",
       "6                        peter, was playing with dog      0   \n",
       "7  Tesla is going to acquire twitter for $45 billion      1   \n",
       "8     Michael Blooberg founded Blommerg L.P. in 1982      1   \n",
       "\n",
       "                                               Token  \\\n",
       "0                [The, cat, sat, on, the, good, mat]   \n",
       "1                [The, dog, lay, on, the, good, rug]   \n",
       "2                     [The, cat, chased, the, mouse]   \n",
       "3  [Apple, is, a, good,, but, I, prefer, Orange, ...   \n",
       "4                   [The, dog, barked, at, the, cat]   \n",
       "5                    [cat, was, drinking, the, milk]   \n",
       "6                  [peter,, was, playing, with, dog]   \n",
       "7  [Tesla, is, going, to, acquire, twitter, for, ...   \n",
       "8  [Michael, Blooberg, founded, Blommerg, L.P., i...   \n",
       "\n",
       "                                        lema  \\\n",
       "0                           cat sit good mat   \n",
       "1                           dog lie good rug   \n",
       "2                            cat chase mouse   \n",
       "3           Apple good prefer Orange product   \n",
       "4                               dog bark cat   \n",
       "5                             cat drink milk   \n",
       "6                             peter play dog   \n",
       "7      Tesla go acquire twitter $ 45 billion   \n",
       "8  Michael Blooberg found Blommerg L.P. 1982   \n",
       "\n",
       "                                         lema_token  \n",
       "0                             [cat, sit, good, mat]  \n",
       "1                             [dog, lie, good, rug]  \n",
       "2                               [cat, chase, mouse]  \n",
       "3            [Apple, good, prefer, Orange, product]  \n",
       "4                                  [dog, bark, cat]  \n",
       "5                                [cat, drink, milk]  \n",
       "6                                [peter, play, dog]  \n",
       "7     [Tesla, go, acquire, twitter, $, 45, billion]  \n",
       "8  [Michael, Blooberg, found, Blommerg, L.P., 1982]  "
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"lema_token\"]=df[\"lema\"].apply(tokenization)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2073cc25",
   "metadata": {},
   "source": [
    "### Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "d2ce8bea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cat': 8,\n",
       " 'sit': 26,\n",
       " 'good': 14,\n",
       " 'mat': 16,\n",
       " 'dog': 10,\n",
       " 'lie': 15,\n",
       " 'rug': 25,\n",
       " 'chase': 9,\n",
       " 'mouse': 19,\n",
       " 'apple': 3,\n",
       " 'prefer': 23,\n",
       " 'orange': 20,\n",
       " 'product': 24,\n",
       " 'bark': 4,\n",
       " 'drink': 11,\n",
       " 'milk': 18,\n",
       " 'peter': 21,\n",
       " 'play': 22,\n",
       " 'tesla': 27,\n",
       " 'go': 13,\n",
       " 'acquire': 2,\n",
       " 'twitter': 28,\n",
       " '45': 1,\n",
       " 'billion': 5,\n",
       " 'michael': 17,\n",
       " 'blooberg': 7,\n",
       " 'found': 12,\n",
       " 'blommerg': 6,\n",
       " '1982': 0}"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "v=CountVectorizer(ngram_range=(1,1))\n",
    "v.fit(df[\"lema\"])\n",
    "vocab=v.vocabulary_\n",
    "vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6babcfa5",
   "metadata": {},
   "source": [
    "# POS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "ee11c585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat | NOUN |  noun |  NN |  noun, singular or mass\n",
      "was | AUX |  auxiliary |  VBD |  verb, past tense\n",
      "drinking | VERB |  verb |  VBG |  verb, gerund or present participle\n",
      "the | DET |  determiner |  DT |  determiner\n",
      "milk | NOUN |  noun |  NN |  noun, singular or mass\n",
      "Tesla | PROPN |  proper noun |  NNP |  noun, proper singular\n",
      "is | AUX |  auxiliary |  VBZ |  verb, 3rd person singular present\n",
      "going | VERB |  verb |  VBG |  verb, gerund or present participle\n",
      "to | PART |  particle |  TO |  infinitival \"to\"\n",
      "acquire | VERB |  verb |  VB |  verb, base form\n",
      "twitter | NOUN |  noun |  NN |  noun, singular or mass\n",
      "for | ADP |  adposition |  IN |  conjunction, subordinating or preposition\n",
      "$ | SYM |  symbol |  $ |  symbol, currency\n",
      "45 | NUM |  numeral |  CD |  cardinal number\n",
      "billion | NUM |  numeral |  CD |  cardinal number\n",
      "The | DET |  determiner |  DT |  determiner\n",
      "dog | NOUN |  noun |  NN |  noun, singular or mass\n",
      "lay | VERB |  verb |  VBD |  verb, past tense\n",
      "on | ADP |  adposition |  IN |  conjunction, subordinating or preposition\n",
      "the | DET |  determiner |  DT |  determiner\n",
      "good | ADJ |  adjective |  JJ |  adjective (English), other noun-modifier (Chinese)\n",
      "rug | NOUN |  noun |  NN |  noun, singular or mass\n",
      "peter | PROPN |  proper noun |  NNP |  noun, proper singular\n",
      ", | PUNCT |  punctuation |  , |  punctuation mark, comma\n",
      "was | AUX |  auxiliary |  VBD |  verb, past tense\n",
      "playing | VERB |  verb |  VBG |  verb, gerund or present participle\n",
      "with | ADP |  adposition |  IN |  conjunction, subordinating or preposition\n",
      "dog | NOUN |  noun |  NN |  noun, singular or mass\n",
      "The | DET |  determiner |  DT |  determiner\n",
      "cat | NOUN |  noun |  NN |  noun, singular or mass\n",
      "sat | VERB |  verb |  VBD |  verb, past tense\n",
      "on | ADP |  adposition |  IN |  conjunction, subordinating or preposition\n",
      "the | DET |  determiner |  DT |  determiner\n",
      "good | ADJ |  adjective |  JJ |  adjective (English), other noun-modifier (Chinese)\n",
      "mat | NOUN |  noun |  NN |  noun, singular or mass\n",
      "The | DET |  determiner |  DT |  determiner\n",
      "cat | NOUN |  noun |  NN |  noun, singular or mass\n",
      "chased | VERB |  verb |  VBD |  verb, past tense\n",
      "the | DET |  determiner |  DT |  determiner\n",
      "mouse | NOUN |  noun |  NN |  noun, singular or mass\n",
      "Michael | PROPN |  proper noun |  NNP |  noun, proper singular\n",
      "Blooberg | PROPN |  proper noun |  NNP |  noun, proper singular\n",
      "founded | VERB |  verb |  VBD |  verb, past tense\n",
      "Blommerg | PROPN |  proper noun |  NNP |  noun, proper singular\n",
      "L.P. | PROPN |  proper noun |  NNP |  noun, proper singular\n",
      "in | ADP |  adposition |  IN |  conjunction, subordinating or preposition\n",
      "1982 | NUM |  numeral |  CD |  cardinal number\n",
      "The | DET |  determiner |  DT |  determiner\n",
      "dog | NOUN |  noun |  NN |  noun, singular or mass\n",
      "barked | VERB |  verb |  VBN |  verb, past participle\n",
      "at | ADP |  adposition |  IN |  conjunction, subordinating or preposition\n",
      "the | DET |  determiner |  DT |  determiner\n",
      "cat | NOUN |  noun |  NN |  noun, singular or mass\n",
      "Apple | PROPN |  proper noun |  NNP |  noun, proper singular\n",
      "is | AUX |  auxiliary |  VBZ |  verb, 3rd person singular present\n",
      "a | DET |  determiner |  DT |  determiner\n",
      "good | NOUN |  noun |  NN |  noun, singular or mass\n",
      ", | PUNCT |  punctuation |  , |  punctuation mark, comma\n",
      "but | CCONJ |  coordinating conjunction |  CC |  conjunction, coordinating\n",
      "I | PRON |  pronoun |  PRP |  pronoun, personal\n",
      "prefer | VERB |  verb |  VBP |  verb, non-3rd person singular present\n",
      "Orange | PROPN |  proper noun |  NNP |  noun, proper singular\n",
      "products | NOUN |  noun |  NNS |  noun, plural\n",
      ". | PUNCT |  punctuation |  . |  punctuation mark, sentence closer\n"
     ]
    }
   ],
   "source": [
    "nlp=spacy.load(\"en_core_web_sm\")\n",
    "for sentence in corpus:\n",
    "    doc=nlp(sentence)\n",
    "    for token in doc:\n",
    "        print(token,\"|\",token.pos_,\"| \", spacy.explain(token.pos_),\"| \", token.tag_,\"| \", spacy.explain(token.tag_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37fc42af",
   "metadata": {},
   "source": [
    "### This is problem of pos it was not able to tell that michael blooberg was a person and blommerg was a company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "e1d8c4dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Michael | PROPN |  proper noun |  NNP |  noun, proper singular\n",
      "Blooberg | PROPN |  proper noun |  NNP |  noun, proper singular\n",
      "founded | VERB |  verb |  VBD |  verb, past tense\n",
      "Blommerg | PROPN |  proper noun |  NNP |  noun, proper singular\n",
      "L.P. | PROPN |  proper noun |  NNP |  noun, proper singular\n",
      "in | ADP |  adposition |  IN |  conjunction, subordinating or preposition\n",
      "1982 | NUM |  numeral |  CD |  cardinal number\n"
     ]
    }
   ],
   "source": [
    "doc=nlp(\"Michael Blooberg founded Blommerg L.P. in 1982\")\n",
    "for token in doc:\n",
    "            print(token,\"|\",token.pos_,\"| \", spacy.explain(token.pos_),\"| \", token.tag_,\"| \", spacy.explain(token.tag_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c36fd1b",
   "metadata": {},
   "source": [
    "# NER\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "83f81fc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla | ORG\n",
      "$45 billion | MONEY\n",
      "peter | PERSON\n",
      "Michael Blooberg | PERSON\n",
      "Blommerg L.P. | ORG\n",
      "1982 | DATE\n",
      "Apple | ORG\n",
      "Orange | NORP\n"
     ]
    }
   ],
   "source": [
    "nlp=spacy.load(\"en_core_web_sm\")\n",
    "for sentence in corpus:\n",
    "    doc=nlp(sentence)\n",
    "    for ent in doc.ents:\n",
    "        print(ent.text,\"|\",ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192d93c9",
   "metadata": {},
   "source": [
    "### This is problem of ner it was not able to tell that apple and orange are fruits not company or nationality as it does not consider context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "fe04745d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple | ORG | Companies, agencies, institutions, etc.\n",
      "Orange | NORP | Nationalities or religious or political groups\n"
     ]
    }
   ],
   "source": [
    "doc=nlp(\"Apple is a good, but I prefer Orange products.\")\n",
    "for ent in doc.ents:\n",
    "        print(ent.text,\"|\",ent.label_,\"|\",spacy.explain(ent.label_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8d92d2",
   "metadata": {},
   "source": [
    "# BAG OF WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "9e44b252",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cat': 8,\n",
       " 'chase': 9,\n",
       " 'mouse': 19,\n",
       " 'tesla': 27,\n",
       " 'go': 13,\n",
       " 'acquire': 2,\n",
       " 'twitter': 28,\n",
       " '45': 1,\n",
       " 'billion': 5,\n",
       " 'michael': 17,\n",
       " 'blooberg': 7,\n",
       " 'found': 12,\n",
       " 'blommerg': 6,\n",
       " '1982': 0,\n",
       " 'dog': 10,\n",
       " 'bark': 4,\n",
       " 'apple': 3,\n",
       " 'good': 14,\n",
       " 'prefer': 23,\n",
       " 'orange': 20,\n",
       " 'product': 24,\n",
       " 'peter': 21,\n",
       " 'play': 22,\n",
       " 'lie': 15,\n",
       " 'rug': 25,\n",
       " 'drink': 11,\n",
       " 'milk': 18,\n",
       " 'sit': 26,\n",
       " 'mat': 16}"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v=CountVectorizer(ngram_range=(1,1))\n",
    "v.fit(lemmatized_corpus)\n",
    "v.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "aed409ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 1, 1],\n",
       "       [1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0,\n",
       "        0, 1, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "        1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 1, 0, 0]])"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.transform(lemmatized_corpus).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e958e37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2df5ab57",
   "metadata": {},
   "source": [
    "# N BAG OF WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "cd06bc10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cat': 17,\n",
       " 'chase': 24,\n",
       " 'mouse': 52,\n",
       " 'cat chase': 18,\n",
       " 'chase mouse': 25,\n",
       " 'cat chase mouse': 19,\n",
       " 'tesla': 68,\n",
       " 'go': 36,\n",
       " 'acquire': 3,\n",
       " 'twitter': 71,\n",
       " '45': 1,\n",
       " 'billion': 11,\n",
       " 'tesla go': 69,\n",
       " 'go acquire': 37,\n",
       " 'acquire twitter': 4,\n",
       " 'twitter 45': 72,\n",
       " '45 billion': 2,\n",
       " 'tesla go acquire': 70,\n",
       " 'go acquire twitter': 38,\n",
       " 'acquire twitter 45': 5,\n",
       " 'twitter 45 billion': 73,\n",
       " 'michael': 48,\n",
       " 'blooberg': 14,\n",
       " 'found': 33,\n",
       " 'blommerg': 12,\n",
       " '1982': 0,\n",
       " 'michael blooberg': 49,\n",
       " 'blooberg found': 15,\n",
       " 'found blommerg': 34,\n",
       " 'blommerg 1982': 13,\n",
       " 'michael blooberg found': 50,\n",
       " 'blooberg found blommerg': 16,\n",
       " 'found blommerg 1982': 35,\n",
       " 'dog': 26,\n",
       " 'bark': 9,\n",
       " 'dog bark': 27,\n",
       " 'bark cat': 10,\n",
       " 'dog bark cat': 28,\n",
       " 'apple': 6,\n",
       " 'good': 39,\n",
       " 'prefer': 60,\n",
       " 'orange': 53,\n",
       " 'product': 63,\n",
       " 'apple good': 7,\n",
       " 'good prefer': 41,\n",
       " 'prefer orange': 61,\n",
       " 'orange product': 54,\n",
       " 'apple good prefer': 8,\n",
       " 'good prefer orange': 42,\n",
       " 'prefer orange product': 62,\n",
       " 'peter': 55,\n",
       " 'play': 58,\n",
       " 'peter play': 56,\n",
       " 'play dog': 59,\n",
       " 'peter play dog': 57,\n",
       " 'lie': 44,\n",
       " 'rug': 64,\n",
       " 'dog lie': 29,\n",
       " 'lie good': 45,\n",
       " 'good rug': 43,\n",
       " 'dog lie good': 30,\n",
       " 'lie good rug': 46,\n",
       " 'drink': 31,\n",
       " 'milk': 51,\n",
       " 'cat drink': 20,\n",
       " 'drink milk': 32,\n",
       " 'cat drink milk': 21,\n",
       " 'sit': 65,\n",
       " 'mat': 47,\n",
       " 'cat sit': 22,\n",
       " 'sit good': 66,\n",
       " 'good mat': 40,\n",
       " 'cat sit good': 23,\n",
       " 'sit good mat': 67}"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v=CountVectorizer(ngram_range=(1,3))\n",
    "v.fit(lemmatized_corpus)\n",
    "v.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "018d3aef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0,\n",
       "        0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 1, 1, 1, 1, 1],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "        1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "        1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
       "        0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "        1, 1, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.transform(lemmatized_corpus).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb9bcfc",
   "metadata": {},
   "source": [
    "# TF-IDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "7cb43010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cat': 8, 'chase': 9, 'mouse': 19, 'tesla': 27, 'go': 13, 'acquire': 2, 'twitter': 28, '45': 1, 'billion': 5, 'michael': 17, 'blooberg': 7, 'found': 12, 'blommerg': 6, '1982': 0, 'dog': 10, 'bark': 4, 'apple': 3, 'good': 14, 'prefer': 23, 'orange': 20, 'product': 24, 'peter': 21, 'play': 22, 'lie': 15, 'rug': 25, 'drink': 11, 'milk': 18, 'sit': 26, 'mat': 16}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "v=TfidfVectorizer()\n",
    "transformed_output=v.fit_transform(lemmatized_corpus)\n",
    "print(v.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "1175b99b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.41701261, 0.64268985,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.64268985,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.40824829, 0.40824829, 0.        , 0.        ,\n",
       "        0.40824829, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.40824829, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.40824829, 0.40824829],\n",
       "       [0.4472136 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.4472136 , 0.4472136 , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.4472136 , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.4472136 , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.71422904,\n",
       "        0.        , 0.        , 0.        , 0.46343118, 0.        ,\n",
       "        0.52450778, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.46935954, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.34468317,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.46935954, 0.        , 0.        , 0.46935954, 0.46935954,\n",
       "        0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.46084788, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.62754252, 0.62754252, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.41854106, 0.        , 0.        , 0.        , 0.41854106,\n",
       "        0.56993279, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.56993279, 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.41701261, 0.        ,\n",
       "        0.        , 0.64268985, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.64268985, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.37711957, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.42682098,\n",
       "        0.        , 0.58120766, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.58120766, 0.        , 0.        ]])"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_output.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "8003daed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1982', '45', 'acquire', 'apple', 'bark', 'billion', 'blommerg',\n",
       "       'blooberg', 'cat', 'chase', 'dog', 'drink', 'found', 'go', 'good',\n",
       "       'lie', 'mat', 'michael', 'milk', 'mouse', 'orange', 'peter',\n",
       "       'play', 'prefer', 'product', 'rug', 'sit', 'tesla', 'twitter'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_feature=v.get_feature_names_out()  # gives vocabulary in oder\n",
    "all_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "7cd5a957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1982 2.6094379124341005\n",
      "45 2.6094379124341005\n",
      "acquire 2.6094379124341005\n",
      "apple 2.6094379124341005\n",
      "bark 2.6094379124341005\n",
      "billion 2.6094379124341005\n",
      "blommerg 2.6094379124341005\n",
      "blooberg 2.6094379124341005\n",
      "cat 1.6931471805599454\n",
      "chase 2.6094379124341005\n",
      "dog 1.916290731874155\n",
      "drink 2.6094379124341005\n",
      "found 2.6094379124341005\n",
      "go 2.6094379124341005\n",
      "good 1.916290731874155\n",
      "lie 2.6094379124341005\n",
      "mat 2.6094379124341005\n",
      "michael 2.6094379124341005\n",
      "milk 2.6094379124341005\n",
      "mouse 2.6094379124341005\n",
      "orange 2.6094379124341005\n",
      "peter 2.6094379124341005\n",
      "play 2.6094379124341005\n",
      "prefer 2.6094379124341005\n",
      "product 2.6094379124341005\n",
      "rug 2.6094379124341005\n",
      "sit 2.6094379124341005\n",
      "tesla 2.6094379124341005\n",
      "twitter 2.6094379124341005\n"
     ]
    }
   ],
   "source": [
    "for word in all_feature:\n",
    "    indx=v.vocabulary_.get(word)\n",
    "    score=v.idf_[indx] #IDF tells us the weight or importance of a word across all documents.\n",
    "    print(word,score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "770caa7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.41701261, 0.64268985,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.64268985,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.40824829, 0.40824829, 0.        , 0.        ,\n",
       "        0.40824829, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.40824829, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.40824829, 0.40824829],\n",
       "       [0.4472136 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.4472136 , 0.4472136 , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.4472136 , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.4472136 , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.71422904,\n",
       "        0.        , 0.        , 0.        , 0.46343118, 0.        ,\n",
       "        0.52450778, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.46935954, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.34468317,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.46935954, 0.        , 0.        , 0.46935954, 0.46935954,\n",
       "        0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.46084788, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.62754252, 0.62754252, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.41854106, 0.        , 0.        , 0.        , 0.41854106,\n",
       "        0.56993279, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.56993279, 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.41701261, 0.        ,\n",
       "        0.        , 0.64268985, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.64268985, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.37711957, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.42682098,\n",
       "        0.        , 0.58120766, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.58120766, 0.        , 0.        ]])"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_output.toarray() # constructing tfid for each sentence. using index position\n",
    "                             # score is higher for rare element and lower for frequent occuring\n",
    "    #TF-IDF combines IDF with the terms frequency in a specific document to calculate its relevance in that document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "53fd0f28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>label</th>\n",
       "      <th>Token</th>\n",
       "      <th>lema</th>\n",
       "      <th>lema_token</th>\n",
       "      <th>sentence_embedding</th>\n",
       "      <th>tfidf_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The cat sat on the good mat</td>\n",
       "      <td>0</td>\n",
       "      <td>[The, cat, sat, on, the, good, mat]</td>\n",
       "      <td>cat sit good mat</td>\n",
       "      <td>[cat, sit, good, mat]</td>\n",
       "      <td>[-4.296632867543307, -3.4300067188059913, -1.9...</td>\n",
       "      <td>[0.44658685, -0.69135404, -0.0017491952, -0.51...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The dog lay on the good rug</td>\n",
       "      <td>1</td>\n",
       "      <td>[The, dog, lay, on, the, good, rug]</td>\n",
       "      <td>dog lie good rug</td>\n",
       "      <td>[dog, lie, good, rug]</td>\n",
       "      <td>[-4.738853494951768, -3.2760543845549246, -3.1...</td>\n",
       "      <td>[0.5090586, -0.9326261, 0.4606844, -0.08693685...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The cat chased the mouse</td>\n",
       "      <td>0</td>\n",
       "      <td>[The, cat, chased, the, mouse]</td>\n",
       "      <td>cat chase mouse</td>\n",
       "      <td>[cat, chase, mouse]</td>\n",
       "      <td>[1.1724748867906267, 0.550760702030434, 1.0257...</td>\n",
       "      <td>[-0.35758713, -0.9874146, 0.6990876, 0.2098652...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Apple is a good, but I prefer Orange products.</td>\n",
       "      <td>1</td>\n",
       "      <td>[Apple, is, a, good,, but, I, prefer, Orange, ...</td>\n",
       "      <td>Apple good prefer Orange product</td>\n",
       "      <td>[Apple, good, prefer, Orange, product]</td>\n",
       "      <td>[-14.809958700664838, -11.215513791799088, -11...</td>\n",
       "      <td>[-0.0028217435, -0.9776285, -0.17968778, 0.142...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The dog barked at the cat</td>\n",
       "      <td>1</td>\n",
       "      <td>[The, dog, barked, at, the, cat]</td>\n",
       "      <td>dog bark cat</td>\n",
       "      <td>[dog, bark, cat]</td>\n",
       "      <td>[0.27359209231933174, 0.2635787607001398, 0.50...</td>\n",
       "      <td>[-0.08661825, -1.0619875, 0.44906196, 0.564633...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cat was drinking the milk</td>\n",
       "      <td>0</td>\n",
       "      <td>[cat, was, drinking, the, milk]</td>\n",
       "      <td>cat drink milk</td>\n",
       "      <td>[cat, drink, milk]</td>\n",
       "      <td>[0.6922010044068547, 0.36107065406917616, 1.81...</td>\n",
       "      <td>[-0.5067006, -0.69687396, 0.07482315, -0.10917...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>peter, was playing with dog</td>\n",
       "      <td>0</td>\n",
       "      <td>[peter,, was, playing, with, dog]</td>\n",
       "      <td>peter play dog</td>\n",
       "      <td>[peter, play, dog]</td>\n",
       "      <td>[-0.16176466128310363, 0.37738073174769066, -0...</td>\n",
       "      <td>[-0.18020652, -0.7468036, 0.08205422, 0.309880...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Tesla is going to acquire twitter for $45 billion</td>\n",
       "      <td>1</td>\n",
       "      <td>[Tesla, is, going, to, acquire, twitter, for, ...</td>\n",
       "      <td>Tesla go acquire twitter $ 45 billion</td>\n",
       "      <td>[Tesla, go, acquire, twitter, $, 45, billion]</td>\n",
       "      <td>[-9.027906575971008, -6.167464441584448, -6.99...</td>\n",
       "      <td>[-0.5984076, -0.35710755, 0.51680726, 0.033701...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Michael Blooberg founded Blommerg L.P. in 1982</td>\n",
       "      <td>1</td>\n",
       "      <td>[Michael, Blooberg, founded, Blommerg, L.P., i...</td>\n",
       "      <td>Michael Blooberg found Blommerg L.P. 1982</td>\n",
       "      <td>[Michael, Blooberg, found, Blommerg, L.P., 1982]</td>\n",
       "      <td>[-23.37997013001771, -16.96360514470485, -17.4...</td>\n",
       "      <td>[0.08060862, -0.62851846, 0.42036834, 0.212501...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  label  \\\n",
       "0                        The cat sat on the good mat      0   \n",
       "1                        The dog lay on the good rug      1   \n",
       "2                           The cat chased the mouse      0   \n",
       "3     Apple is a good, but I prefer Orange products.      1   \n",
       "4                          The dog barked at the cat      1   \n",
       "5                          cat was drinking the milk      0   \n",
       "6                        peter, was playing with dog      0   \n",
       "7  Tesla is going to acquire twitter for $45 billion      1   \n",
       "8     Michael Blooberg founded Blommerg L.P. in 1982      1   \n",
       "\n",
       "                                               Token  \\\n",
       "0                [The, cat, sat, on, the, good, mat]   \n",
       "1                [The, dog, lay, on, the, good, rug]   \n",
       "2                     [The, cat, chased, the, mouse]   \n",
       "3  [Apple, is, a, good,, but, I, prefer, Orange, ...   \n",
       "4                   [The, dog, barked, at, the, cat]   \n",
       "5                    [cat, was, drinking, the, milk]   \n",
       "6                  [peter,, was, playing, with, dog]   \n",
       "7  [Tesla, is, going, to, acquire, twitter, for, ...   \n",
       "8  [Michael, Blooberg, founded, Blommerg, L.P., i...   \n",
       "\n",
       "                                        lema  \\\n",
       "0                           cat sit good mat   \n",
       "1                           dog lie good rug   \n",
       "2                            cat chase mouse   \n",
       "3           Apple good prefer Orange product   \n",
       "4                               dog bark cat   \n",
       "5                             cat drink milk   \n",
       "6                             peter play dog   \n",
       "7      Tesla go acquire twitter $ 45 billion   \n",
       "8  Michael Blooberg found Blommerg L.P. 1982   \n",
       "\n",
       "                                         lema_token  \\\n",
       "0                             [cat, sit, good, mat]   \n",
       "1                             [dog, lie, good, rug]   \n",
       "2                               [cat, chase, mouse]   \n",
       "3            [Apple, good, prefer, Orange, product]   \n",
       "4                                  [dog, bark, cat]   \n",
       "5                                [cat, drink, milk]   \n",
       "6                                [peter, play, dog]   \n",
       "7     [Tesla, go, acquire, twitter, $, 45, billion]   \n",
       "8  [Michael, Blooberg, found, Blommerg, L.P., 1982]   \n",
       "\n",
       "                                  sentence_embedding  \\\n",
       "0  [-4.296632867543307, -3.4300067188059913, -1.9...   \n",
       "1  [-4.738853494951768, -3.2760543845549246, -3.1...   \n",
       "2  [1.1724748867906267, 0.550760702030434, 1.0257...   \n",
       "3  [-14.809958700664838, -11.215513791799088, -11...   \n",
       "4  [0.27359209231933174, 0.2635787607001398, 0.50...   \n",
       "5  [0.6922010044068547, 0.36107065406917616, 1.81...   \n",
       "6  [-0.16176466128310363, 0.37738073174769066, -0...   \n",
       "7  [-9.027906575971008, -6.167464441584448, -6.99...   \n",
       "8  [-23.37997013001771, -16.96360514470485, -17.4...   \n",
       "\n",
       "                                        tfidf_vector  \n",
       "0  [0.44658685, -0.69135404, -0.0017491952, -0.51...  \n",
       "1  [0.5090586, -0.9326261, 0.4606844, -0.08693685...  \n",
       "2  [-0.35758713, -0.9874146, 0.6990876, 0.2098652...  \n",
       "3  [-0.0028217435, -0.9776285, -0.17968778, 0.142...  \n",
       "4  [-0.08661825, -1.0619875, 0.44906196, 0.564633...  \n",
       "5  [-0.5067006, -0.69687396, 0.07482315, -0.10917...  \n",
       "6  [-0.18020652, -0.7468036, 0.08205422, 0.309880...  \n",
       "7  [-0.5984076, -0.35710755, 0.51680726, 0.033701...  \n",
       "8  [0.08060862, -0.62851846, 0.42036834, 0.212501...  "
      ]
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_vector(text):\n",
    "    return nlp(text).vector # Returns the dense vector representation (embedding) of the entire input text. This vector is typically a fixed-dimensional representation of the text computed by averaging the word embeddings of individual tokens (depending on the model).\n",
    "\n",
    "# Apply the function to the 'text' column\n",
    "df['tfidf_vector'] = df['lema'].apply(compute_vector)\n",
    "df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "1b6406b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x = np.array(df['tfidf_vector'].to_list())  # Convert to 2D numpy array\n",
    "y = df['label'].values \n",
    "x_train,x_test,y_train,y_test=train_test_split(\n",
    "    x,y,\n",
    "    test_size=0.3,\n",
    "    random_state=2020,\n",
    "    \n",
    ")\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf=KNeighborsClassifier()\n",
    "clf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "3fcc08e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      1.00      0.50         1\n",
      "           1       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.33         3\n",
      "   macro avg       0.17      0.50      0.25         3\n",
      "weighted avg       0.11      0.33      0.17         3\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aditisinha/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/aditisinha/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/aditisinha/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/aditisinha/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_pred=clf.predict(x_test)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691c7849",
   "metadata": {},
   "source": [
    "### This fails in case of similar words it creates different vector score for two similar meaning word\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8d6625",
   "metadata": {},
   "source": [
    "#### good and great have same meaning but still it is not able to fill great instead of good "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "beec304b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Sentence Vector (TF-IDF):\n",
      " [[0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.54431302 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.8388822  0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "new_sentence = \"cat sat on the great mat\"  # was not able to gain context \n",
    "\n",
    "# Transform the new sentence using the fitted vectorizer\n",
    "new_sentence_vector = v.transform([new_sentence])\n",
    "\n",
    "# Display the resulting vector\n",
    "print(\"New Sentence Vector (TF-IDF):\\n\", new_sentence_vector.toarray())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "5c302199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Sentence Vector (TF-IDF):\n",
      " [[0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.46343118 0.         0.         0.\n",
      "  0.         0.         0.52450778 0.         0.71422904 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "new_sentence = \"cat sat on the good mat\"\n",
    "\n",
    "# Transform the new sentence using the fitted vectorizer\n",
    "new_sentence_vector = v.transform([new_sentence])\n",
    "\n",
    "# Display the resulting vector\n",
    "print(\"New Sentence Vector (TF-IDF):\\n\", new_sentence_vector.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dda9529",
   "metadata": {},
   "source": [
    "# EMBEDDING CBOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "7b7add76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: ['sit', 'good'] -> Target: cat\n",
      "Context: ['cat', 'good', 'mat'] -> Target: sit\n",
      "Context: ['cat', 'sit', 'mat'] -> Target: good\n",
      "Context: ['sit', 'good'] -> Target: mat\n",
      "Context: ['lie', 'good'] -> Target: dog\n",
      "Context: ['dog', 'good', 'rug'] -> Target: lie\n",
      "Context: ['dog', 'lie', 'rug'] -> Target: good\n",
      "Context: ['lie', 'good'] -> Target: rug\n",
      "Context: ['chase', 'mouse'] -> Target: cat\n",
      "Context: ['cat', 'mouse'] -> Target: chase\n",
      "Context: ['cat', 'chase'] -> Target: mouse\n",
      "Context: ['good', 'prefer'] -> Target: Apple\n",
      "Context: ['Apple', 'prefer', 'Orange'] -> Target: good\n",
      "Context: ['Apple', 'good', 'Orange', 'product'] -> Target: prefer\n",
      "Context: ['good', 'prefer', 'product'] -> Target: Orange\n",
      "Context: ['prefer', 'Orange'] -> Target: product\n",
      "Context: ['bark', 'cat'] -> Target: dog\n",
      "Context: ['dog', 'cat'] -> Target: bark\n",
      "Context: ['dog', 'bark'] -> Target: cat\n",
      "Context: ['drink', 'milk'] -> Target: cat\n",
      "Context: ['cat', 'milk'] -> Target: drink\n",
      "Context: ['cat', 'drink'] -> Target: milk\n",
      "Context: ['play', 'dog'] -> Target: peter\n",
      "Context: ['peter', 'dog'] -> Target: play\n",
      "Context: ['peter', 'play'] -> Target: dog\n",
      "Context: ['go', 'acquire'] -> Target: Tesla\n",
      "Context: ['Tesla', 'acquire', 'twitter'] -> Target: go\n",
      "Context: ['Tesla', 'go', 'twitter', '$'] -> Target: acquire\n",
      "Context: ['go', 'acquire', '$', '45'] -> Target: twitter\n",
      "Context: ['acquire', 'twitter', '45', 'billion'] -> Target: $\n",
      "Context: ['twitter', '$', 'billion'] -> Target: 45\n",
      "Context: ['$', '45'] -> Target: billion\n",
      "Context: ['Blooberg', 'found'] -> Target: Michael\n",
      "Context: ['Michael', 'found', 'Blommerg'] -> Target: Blooberg\n",
      "Context: ['Michael', 'Blooberg', 'Blommerg', 'L.P.'] -> Target: found\n",
      "Context: ['Blooberg', 'found', 'L.P.', '1982'] -> Target: Blommerg\n",
      "Context: ['found', 'Blommerg', '1982'] -> Target: L.P.\n",
      "Context: ['Blommerg', 'L.P.'] -> Target: 1982\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Generate Training Data for CBOW\n",
    "def generate_training_data(sentences, window_size=2):\n",
    "    data = []\n",
    "    for sentence in sentences:\n",
    "        for idx, word in enumerate(sentence):\n",
    "            # Define context window\n",
    "            context = []\n",
    "            for offset in range(-window_size, window_size + 1):\n",
    "                if offset == 0 or idx + offset < 0 or idx + offset >= len(sentence):\n",
    "                    continue\n",
    "                context.append(sentence[idx + offset])  # Collect words in context\n",
    "            data.append((context, word))  # Add context and target word as tuple\n",
    "    return data\n",
    "\n",
    "# Example sentences (your tokenized or lemmatized sentences)\n",
    "sentences =df[\"lema_token\"]\n",
    "\n",
    "# Define window size (context size)\n",
    "window_size = 2\n",
    "\n",
    "# Generate training data using the function\n",
    "training_data = generate_training_data(sentences, window_size)\n",
    "\n",
    "# Print the training data (context, target word pairs)\n",
    "for context, target in training_data:\n",
    "    print(f\"Context: {context} -> Target: {target}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150b694e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "e0799d7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary: {'cat': 8, 'sit': 26, 'good': 14, 'mat': 16, 'dog': 10, 'lie': 15, 'rug': 25, 'chase': 9, 'mouse': 19, 'apple': 3, 'prefer': 23, 'orange': 20, 'product': 24, 'bark': 4, 'drink': 11, 'milk': 18, 'peter': 21, 'play': 22, 'tesla': 27, 'go': 13, 'acquire': 2, 'twitter': 28, '45': 1, 'billion': 5, 'michael': 17, 'blooberg': 7, 'found': 12, 'blommerg': 6, '1982': 0}\n",
      "Example X_train (context vectors): [[0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.5        0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.5        0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.33333333 0.         0.         0.\n",
      "  0.         0.         0.33333333 0.         0.33333333 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.33333333 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.33333333 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.33333333 0.         0.        ]]\n",
      "Example y_train (target vectors): [[0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "vocab_size=len(vocab)\n",
    "def one_hot_encode(word, vocab_size, vocab):\n",
    "\n",
    "    vec = np.zeros(vocab_size)\n",
    "    index = vocab.get(word)  # Get index of the word\n",
    "    if index is not None:\n",
    "        vec[index] = 1\n",
    "    return vec\n",
    "\n",
    "# Step 4: Prepare training data (X_train, y_train)\n",
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "for context, target in training_data:\n",
    "    context_vectors = np.mean(\n",
    "        [one_hot_encode(word, vocab_size, vocab) for word in context],\n",
    "        axis=0\n",
    "    )\n",
    "    X_train.append(context_vectors)  # Average context vectors\n",
    "    y_train.append(one_hot_encode(target, vocab_size, vocab))  # Target word\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "# Output the one-hot encoded vectors for context and target\n",
    "print(\"Vocabulary:\", vocab)\n",
    "print(\"Example X_train (context vectors):\", X_train[:3])  # Show first 3 context vectors\n",
    "print(\"Example y_train (target vectors):\", y_train[:3]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91366521",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "21328e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100, Loss: 72.9180\n",
      "Epoch 200, Loss: 50.4246\n",
      "Epoch 300, Loss: 33.4638\n",
      "Epoch 400, Loss: 24.2882\n",
      "Epoch 500, Loss: 20.4325\n",
      "Epoch 600, Loss: 18.3901\n",
      "Epoch 700, Loss: 17.0111\n",
      "Epoch 800, Loss: 16.5049\n",
      "Epoch 900, Loss: 18.0451\n",
      "Epoch 1000, Loss: 26.0069\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Train CBOW Model\n",
    "embedding_dim = 10\n",
    "learning_rate = 0.01\n",
    "epochs = 1000\n",
    "\n",
    "# Initialize weights\n",
    "W1 = np.random.rand(vocab_size, embedding_dim)\n",
    "W2 = np.random.rand(embedding_dim, vocab_size)\n",
    "\n",
    "# Softmax function\n",
    "def softmax(x):\n",
    "    exp_x = np.exp(x - np.max(x))  # Stability trick\n",
    "    return exp_x / exp_x.sum(axis=0)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    loss = 0\n",
    "    for x, y in zip(X_train, y_train):\n",
    "        # Forward pass\n",
    "        hidden = np.dot(x, W1)  # Input -> Hidden\n",
    "        output = softmax(np.dot(hidden, W2))  # Hidden -> Output\n",
    "\n",
    "        # Compute loss (cross-entropy)\n",
    "        loss += -np.sum(y * np.log(output))\n",
    "\n",
    "        # Backward pass\n",
    "        error = output - y\n",
    "        dW2 = np.outer(hidden, error)\n",
    "        dW1 = np.outer(x, np.dot(W2, error))\n",
    "\n",
    "        # Update weights\n",
    "        W1 -= learning_rate * dW1\n",
    "        W2 -= learning_rate * dW2\n",
    "\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(f\"Epoch {epoch + 1}, Loss: {loss:.4f}\")\n",
    "\n",
    "# Save word embeddings\n",
    "word_embeddings = {word: W1[vocab[word]] for word in vocab}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f94acd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "2c7afbbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cat': array([-1.02517284,  1.19177745,  3.15856402, -0.98837161,  1.23414171,\n",
       "         1.30423002, -1.40948848, -0.53241064,  1.74360404,  0.16879537]),\n",
       " 'sit': array([ 1.5174755 , -0.08217617,  0.68999159,  0.34118686,  1.1537998 ,\n",
       "         2.28059336,  1.68326367,  1.02355811,  2.23224919, -0.97962486]),\n",
       " 'good': array([-17.85715484, -15.96592237, -14.22101138,  -9.94521133,\n",
       "        -18.80080221, -10.44396608,  -5.46507517, -11.07840271,\n",
       "         -8.51001618,  -7.81261581]),\n",
       " 'mat': array([ 0.17832071,  1.13629421,  2.47881224,  3.0303404 ,  0.08573298,\n",
       "        -0.0987675 ,  1.383535  , -1.05307498,  0.73770686, -0.4878286 ]),\n",
       " 'dog': array([ 0.0537585 ,  0.50809972, -0.87019427, -0.77512937,  1.63865629,\n",
       "        -0.63673703,  1.62594566,  3.56338458,  0.8231708 , -1.9612921 ]),\n",
       " 'lie': array([-0.36151056,  0.95108762,  0.76684266,  3.46855487,  0.0130086 ,\n",
       "         1.86410364,  0.76233592,  0.93903157,  1.44259809,  2.2746167 ]),\n",
       " 'rug': array([-0.79050708,  1.40251749,  1.59801495,  2.49069103, -0.06309557,\n",
       "         0.46386355,  1.53050969,  1.19500236,  0.80998717, -0.53295697]),\n",
       " 'chase': array([ 1.86835232,  0.62672437, -0.43183631, -0.69452795,  1.59868623,\n",
       "         1.92876453, -0.28285234, -0.3663331 ,  0.27474799,  1.45564299]),\n",
       " 'mouse': array([ 2.67424518, -0.16621972,  0.35050929, -1.53226073, -0.63988297,\n",
       "         1.53483216,  1.04900673,  2.65894168, -0.80643764,  0.48725935]),\n",
       " 'apple': array([0.46545161, 0.94380091, 0.18857791, 0.34764236, 0.65525833,\n",
       "        0.53327694, 0.17164708, 0.64548371, 0.83531108, 0.18720288]),\n",
       " 'prefer': array([-20.39463849, -12.24171304, -13.93157445,  -8.30957052,\n",
       "        -17.39089938, -12.01684656,  -9.71139311,  -8.85147106,\n",
       "         -4.67901552, -10.7357967 ]),\n",
       " 'orange': array([0.14986401, 0.31770582, 0.66870211, 0.14894144, 0.11313889,\n",
       "        0.34801432, 0.30651452, 0.81364773, 0.17529094, 0.89939415]),\n",
       " 'product': array([-6.17808277, -5.43890597, -5.88390641, -3.1865238 , -7.41277304,\n",
       "        -4.81978579, -3.30967129, -5.02891456, -2.97854945, -3.7057754 ]),\n",
       " 'bark': array([ 1.79219061, -0.90914089, -0.7878959 ,  0.91133151,  1.51189188,\n",
       "         0.73202966,  2.18567624,  0.07304467,  1.06763576,  3.47105409]),\n",
       " 'drink': array([ 2.67317025,  0.43323696,  0.7752715 , -1.87506262,  2.27133337,\n",
       "        -1.12194556,  2.15479037,  0.91846363, -0.31470165,  0.43130127]),\n",
       " 'milk': array([ 0.4286056 , -0.54180245,  1.50940608, -0.5579841 ,  0.22011986,\n",
       "        -0.00408979, -0.11090579,  1.01716927,  1.39288796,  1.77954277]),\n",
       " 'peter': array([-0.34315463,  1.29022823, -1.18511026,  0.67790882,  1.98334009,\n",
       "         1.27126306, -0.10886319,  0.81275808, -0.16956994,  0.79965243]),\n",
       " 'play': array([-0.19589786, -0.66618575, -0.20553594,  1.23225534,  1.74244428,\n",
       "        -0.59923204,  0.64924975, -0.71360884,  2.90876815,  1.62705498]),\n",
       " 'tesla': array([0.89480736, 0.75631075, 0.24473958, 0.40654375, 0.52726073,\n",
       "        0.462247  , 0.8049359 , 0.05772463, 0.09271634, 0.25273453]),\n",
       " 'go': array([-12.0475433 ,  -7.00952189,  -7.85303512,  -5.78213936,\n",
       "        -12.34193077,  -6.2180221 ,  -4.86149499,  -5.94294867,\n",
       "         -3.51484455,  -4.77106674]),\n",
       " 'acquire': array([-17.34061148, -12.54453213, -13.38490656,  -8.98063078,\n",
       "        -15.40437884, -11.26061661,  -5.70841266,  -9.37916551,\n",
       "         -6.39281226,  -7.95855959]),\n",
       " 'twitter': array([-3.39557655, -1.40977555, -4.61603938, -3.21204229, -7.76013677,\n",
       "        -4.41397608, -2.10701337, -3.28461567, -1.18100219, -3.87634679]),\n",
       " '45': array([-7.19939398, -4.86632806, -3.57768813, -1.66220138, -2.74910711,\n",
       "        -3.95299452, -3.22415299, -3.110852  , -4.63859516, -1.13446945]),\n",
       " 'billion': array([-5.15640757, -5.00716458, -5.5485039 , -1.62715565, -6.23392075,\n",
       "        -1.59415453, -2.27216792, -2.04534917, -0.20551205, -3.1461869 ]),\n",
       " 'michael': array([0.02864217, 0.400911  , 0.28014276, 0.8999076 , 0.86982318,\n",
       "        0.92551456, 0.21363345, 0.04280677, 0.16526074, 0.43236088]),\n",
       " 'blooberg': array([0.29722489, 0.75361617, 0.72208749, 0.53173309, 0.88164526,\n",
       "        0.21621502, 0.20083297, 0.60825674, 0.87723621, 0.60936111]),\n",
       " 'found': array([-33.22903943, -24.38093745, -25.04360778, -16.38518351,\n",
       "        -31.80049417, -19.72364562, -13.06945582, -17.80485792,\n",
       "        -11.39677917, -15.97761234]),\n",
       " 'blommerg': array([0.60990075, 0.12327851, 0.19100017, 0.37343985, 0.0930878 ,\n",
       "        0.6177662 , 0.71299824, 0.18331935, 0.76361186, 0.37765245]),\n",
       " '1982': array([-13.53090083,  -9.54627284,  -9.93181821,  -6.25209211,\n",
       "        -12.83593864,  -7.6880133 ,  -4.75401556,  -7.27113973,\n",
       "         -4.47271123,  -6.42728699])}"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "38300f74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: cat sit good mat\n",
      "Sentence Embedding: [-4.29663287 -3.43000672 -1.97341088 -1.89051392 -4.08178193 -1.73947755\n",
      " -0.95194124 -2.91008255 -0.94911402 -2.27781847]\n",
      "Sentence: dog lie good rug\n",
      "Sentence Embedding: [-4.73885349 -3.27605438 -3.18158701 -1.1902737  -4.30305822 -2.18818398\n",
      " -0.38657098 -1.34524605 -1.35856503 -2.00806205]\n",
      "Sentence: cat chase mouse\n",
      "Sentence Embedding: [ 1.17247489  0.5507607   1.02574567 -1.0717201   0.73098166  1.58927557\n",
      " -0.2144447   0.58673265  0.40397146  0.70389924]\n",
      "Sentence: Apple good prefer Orange product\n",
      "Sentence Embedding: [-14.8099587  -11.21551379 -11.34549741  -7.14710188 -14.53482487\n",
      "  -9.09353281  -6.16204652  -8.31959611  -5.38919371  -7.41806264]\n",
      "Sentence: dog bark cat\n",
      "Sentence Embedding: [ 0.27359209  0.26357876  0.50015795 -0.28405649  1.46156329  0.46650755\n",
      "  0.80071114  1.03467287  1.2114702   0.55951912]\n",
      "Sentence: cat drink milk\n",
      "Sentence Embedding: [ 0.692201    0.36107065  1.81441387 -1.14047278  1.24186498  0.05939822\n",
      "  0.21146537  0.46774075  0.94059678  0.79321314]\n",
      "Sentence: peter play dog\n",
      "Sentence Embedding: [-0.16176466  0.37738073 -0.75361349  0.37834493  1.78814689  0.01176466\n",
      "  0.72211074  1.22084461  1.18745634  0.15513843]\n",
      "Sentence: Tesla go acquire twitter $ 45 billion\n",
      "Sentence Embedding: [-9.02790658 -6.16746444 -6.99603462 -4.25283389 -8.89789485 -5.48795277\n",
      " -3.63464839 -4.7525862  -3.18655324 -4.17732589]\n",
      "Sentence: Michael Blooberg found Blommerg L.P. 1982\n",
      "Sentence Embedding: [-23.37997013 -16.96360514 -17.487713   -11.31863781 -22.31821641\n",
      " -13.70582946  -8.91173569 -12.53799882  -7.9347452  -11.20244966]\n"
     ]
    }
   ],
   "source": [
    "def sentence_embedding(sentence, word_embeddings, vocab):\n",
    "    words = sentence.split()\n",
    "    embeddings = [word_embeddings[word] for word in words if word in vocab]\n",
    "    if embeddings:\n",
    "        return np.mean(embeddings, axis=0)  # Mean pooling\n",
    "    else:\n",
    "        return np.zeros(W1.shape[1])  # Fallback for unknown words\n",
    "\n",
    "# Example usage to generate sentence embeddings\n",
    "sentence_embeddings = []\n",
    "\n",
    "for sentence in df[\"lema\"]:\n",
    "    embedding = sentence_embedding(sentence, word_embeddings, vocab)\n",
    "    sentence_embeddings.append(embedding)                               \n",
    "    print(f\"Sentence: {sentence}\")\n",
    "    print(f\"Sentence Embedding: {embedding}\")\n",
    "df[\"sentence_embedding\"] = sentence_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "id": "27169eb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Text', 'label', 'Token', 'lema', 'lema_token', 'sentence_embedding',\n",
      "       'tfidf_vector'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "894f1b03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>label</th>\n",
       "      <th>Token</th>\n",
       "      <th>lema</th>\n",
       "      <th>lema_token</th>\n",
       "      <th>sentence_embedding</th>\n",
       "      <th>tfidf_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The cat sat on the good mat</td>\n",
       "      <td>0</td>\n",
       "      <td>[The, cat, sat, on, the, good, mat]</td>\n",
       "      <td>cat sit good mat</td>\n",
       "      <td>[cat, sit, good, mat]</td>\n",
       "      <td>[-4.296632867543307, -3.4300067188059913, -1.9...</td>\n",
       "      <td>[0.44658685, -0.69135404, -0.0017491952, -0.51...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The dog lay on the good rug</td>\n",
       "      <td>1</td>\n",
       "      <td>[The, dog, lay, on, the, good, rug]</td>\n",
       "      <td>dog lie good rug</td>\n",
       "      <td>[dog, lie, good, rug]</td>\n",
       "      <td>[-4.738853494951768, -3.2760543845549246, -3.1...</td>\n",
       "      <td>[0.5090586, -0.9326261, 0.4606844, -0.08693685...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The cat chased the mouse</td>\n",
       "      <td>0</td>\n",
       "      <td>[The, cat, chased, the, mouse]</td>\n",
       "      <td>cat chase mouse</td>\n",
       "      <td>[cat, chase, mouse]</td>\n",
       "      <td>[1.1724748867906267, 0.550760702030434, 1.0257...</td>\n",
       "      <td>[-0.35758713, -0.9874146, 0.6990876, 0.2098652...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Apple is a good, but I prefer Orange products.</td>\n",
       "      <td>1</td>\n",
       "      <td>[Apple, is, a, good,, but, I, prefer, Orange, ...</td>\n",
       "      <td>Apple good prefer Orange product</td>\n",
       "      <td>[Apple, good, prefer, Orange, product]</td>\n",
       "      <td>[-14.809958700664838, -11.215513791799088, -11...</td>\n",
       "      <td>[-0.0028217435, -0.9776285, -0.17968778, 0.142...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The dog barked at the cat</td>\n",
       "      <td>1</td>\n",
       "      <td>[The, dog, barked, at, the, cat]</td>\n",
       "      <td>dog bark cat</td>\n",
       "      <td>[dog, bark, cat]</td>\n",
       "      <td>[0.27359209231933174, 0.2635787607001398, 0.50...</td>\n",
       "      <td>[-0.08661825, -1.0619875, 0.44906196, 0.564633...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cat was drinking the milk</td>\n",
       "      <td>0</td>\n",
       "      <td>[cat, was, drinking, the, milk]</td>\n",
       "      <td>cat drink milk</td>\n",
       "      <td>[cat, drink, milk]</td>\n",
       "      <td>[0.6922010044068547, 0.36107065406917616, 1.81...</td>\n",
       "      <td>[-0.5067006, -0.69687396, 0.07482315, -0.10917...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>peter, was playing with dog</td>\n",
       "      <td>0</td>\n",
       "      <td>[peter,, was, playing, with, dog]</td>\n",
       "      <td>peter play dog</td>\n",
       "      <td>[peter, play, dog]</td>\n",
       "      <td>[-0.16176466128310363, 0.37738073174769066, -0...</td>\n",
       "      <td>[-0.18020652, -0.7468036, 0.08205422, 0.309880...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Tesla is going to acquire twitter for $45 billion</td>\n",
       "      <td>1</td>\n",
       "      <td>[Tesla, is, going, to, acquire, twitter, for, ...</td>\n",
       "      <td>Tesla go acquire twitter $ 45 billion</td>\n",
       "      <td>[Tesla, go, acquire, twitter, $, 45, billion]</td>\n",
       "      <td>[-9.027906575971008, -6.167464441584448, -6.99...</td>\n",
       "      <td>[-0.5984076, -0.35710755, 0.51680726, 0.033701...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Michael Blooberg founded Blommerg L.P. in 1982</td>\n",
       "      <td>1</td>\n",
       "      <td>[Michael, Blooberg, founded, Blommerg, L.P., i...</td>\n",
       "      <td>Michael Blooberg found Blommerg L.P. 1982</td>\n",
       "      <td>[Michael, Blooberg, found, Blommerg, L.P., 1982]</td>\n",
       "      <td>[-23.37997013001771, -16.96360514470485, -17.4...</td>\n",
       "      <td>[0.08060862, -0.62851846, 0.42036834, 0.212501...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  label  \\\n",
       "0                        The cat sat on the good mat      0   \n",
       "1                        The dog lay on the good rug      1   \n",
       "2                           The cat chased the mouse      0   \n",
       "3     Apple is a good, but I prefer Orange products.      1   \n",
       "4                          The dog barked at the cat      1   \n",
       "5                          cat was drinking the milk      0   \n",
       "6                        peter, was playing with dog      0   \n",
       "7  Tesla is going to acquire twitter for $45 billion      1   \n",
       "8     Michael Blooberg founded Blommerg L.P. in 1982      1   \n",
       "\n",
       "                                               Token  \\\n",
       "0                [The, cat, sat, on, the, good, mat]   \n",
       "1                [The, dog, lay, on, the, good, rug]   \n",
       "2                     [The, cat, chased, the, mouse]   \n",
       "3  [Apple, is, a, good,, but, I, prefer, Orange, ...   \n",
       "4                   [The, dog, barked, at, the, cat]   \n",
       "5                    [cat, was, drinking, the, milk]   \n",
       "6                  [peter,, was, playing, with, dog]   \n",
       "7  [Tesla, is, going, to, acquire, twitter, for, ...   \n",
       "8  [Michael, Blooberg, founded, Blommerg, L.P., i...   \n",
       "\n",
       "                                        lema  \\\n",
       "0                           cat sit good mat   \n",
       "1                           dog lie good rug   \n",
       "2                            cat chase mouse   \n",
       "3           Apple good prefer Orange product   \n",
       "4                               dog bark cat   \n",
       "5                             cat drink milk   \n",
       "6                             peter play dog   \n",
       "7      Tesla go acquire twitter $ 45 billion   \n",
       "8  Michael Blooberg found Blommerg L.P. 1982   \n",
       "\n",
       "                                         lema_token  \\\n",
       "0                             [cat, sit, good, mat]   \n",
       "1                             [dog, lie, good, rug]   \n",
       "2                               [cat, chase, mouse]   \n",
       "3            [Apple, good, prefer, Orange, product]   \n",
       "4                                  [dog, bark, cat]   \n",
       "5                                [cat, drink, milk]   \n",
       "6                                [peter, play, dog]   \n",
       "7     [Tesla, go, acquire, twitter, $, 45, billion]   \n",
       "8  [Michael, Blooberg, found, Blommerg, L.P., 1982]   \n",
       "\n",
       "                                  sentence_embedding  \\\n",
       "0  [-4.296632867543307, -3.4300067188059913, -1.9...   \n",
       "1  [-4.738853494951768, -3.2760543845549246, -3.1...   \n",
       "2  [1.1724748867906267, 0.550760702030434, 1.0257...   \n",
       "3  [-14.809958700664838, -11.215513791799088, -11...   \n",
       "4  [0.27359209231933174, 0.2635787607001398, 0.50...   \n",
       "5  [0.6922010044068547, 0.36107065406917616, 1.81...   \n",
       "6  [-0.16176466128310363, 0.37738073174769066, -0...   \n",
       "7  [-9.027906575971008, -6.167464441584448, -6.99...   \n",
       "8  [-23.37997013001771, -16.96360514470485, -17.4...   \n",
       "\n",
       "                                        tfidf_vector  \n",
       "0  [0.44658685, -0.69135404, -0.0017491952, -0.51...  \n",
       "1  [0.5090586, -0.9326261, 0.4606844, -0.08693685...  \n",
       "2  [-0.35758713, -0.9874146, 0.6990876, 0.2098652...  \n",
       "3  [-0.0028217435, -0.9776285, -0.17968778, 0.142...  \n",
       "4  [-0.08661825, -1.0619875, 0.44906196, 0.564633...  \n",
       "5  [-0.5067006, -0.69687396, 0.07482315, -0.10917...  \n",
       "6  [-0.18020652, -0.7468036, 0.08205422, 0.309880...  \n",
       "7  [-0.5984076, -0.35710755, 0.51680726, 0.033701...  \n",
       "8  [0.08060862, -0.62851846, 0.42036834, 0.212501...  "
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "ed65dd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vector_for_word(word, vocab, word_embeddings, nlp_model):\n",
    "    if word in vocab:\n",
    "        return word_embeddings[word]\n",
    "    else:\n",
    "        # Use spaCy to find the closest word in vocabulary\n",
    "        word_doc = nlp_model(word)\n",
    "        best_match = None\n",
    "        highest_similarity = -1  # Initialize with a very low similarity\n",
    "        \n",
    "        for w in vocab:\n",
    "            similarity = nlp_model(w).similarity(word_doc)\n",
    "            print(w,\"  \",word_doc,similarity)\n",
    "            if similarity > highest_similarity:\n",
    "                highest_similarity = similarity\n",
    "                best_match = w\n",
    "        \n",
    "        print(best_match)\n",
    "        return word_embeddings[best_match]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "32cfbdad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence Vector with OOV Handling:\n",
      " [-4.29663287 -3.43000672 -1.97341088 -1.89051392 -4.08178193 -1.73947755\n",
      " -0.95194124 -2.91008255 -0.94911402 -2.27781847]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example usage\n",
    "new_sentence = \"cat sit good mat\"\n",
    "tokens = new_sentence.split()\n",
    "\n",
    "sentence_vector = np.mean(\n",
    "    [get_vector_for_word(word, vocab, word_embeddings, nlp) for word in tokens],\n",
    "    axis=0\n",
    ")\n",
    "\n",
    "print(\"Sentence Vector with OOV Handling:\\n\", sentence_vector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "88b3b96d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat    great 0.17494932238952837\n",
      "sit    great 0.24969802926952261\n",
      "good    great 0.7787824384089056\n",
      "mat    great 0.38119960248173285\n",
      "dog    great 0.34885706900178715\n",
      "lie    great 0.24701933271216805\n",
      "rug    great 0.2959269896398435\n",
      "chase    great 0.3264818430676584\n",
      "mouse    great 0.2715305626544373\n",
      "apple    great 0.27350819127981346\n",
      "prefer    great 0.017942998936631305\n",
      "orange    great 0.4819340458497497\n",
      "product    great 0.30430471958041877\n",
      "bark    great 0.37586858167245396\n",
      "drink    great 0.24296258217542302\n",
      "milk    great 0.23878569036753866\n",
      "peter    great 0.29925606235024854\n",
      "play    great 0.10422958912082037\n",
      "tesla    great 0.3779552529622165\n",
      "go    great 0.2376881286750955\n",
      "acquire    great 0.10534960470122061\n",
      "twitter    great 0.0950113498008723\n",
      "45    great 0.22742329913757364\n",
      "billion    great 0.2691890682415729\n",
      "michael    great 0.2750678895699965\n",
      "blooberg    great 0.23578071152692218\n",
      "found    great 0.27760391549651653\n",
      "blommerg    great 0.28841831805076884\n",
      "1982    great 0.08671371948398507\n",
      "good\n",
      "Sentence Vector with OOV Handling:\n",
      " [-4.29663287 -3.43000672 -1.97341088 -1.89051392 -4.08178193 -1.73947755\n",
      " -0.95194124 -2.91008255 -0.94911402 -2.27781847]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ff/4sk8kzk938178x3h7j_6rb0r0000gn/T/ipykernel_88908/2276827349.py:11: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  similarity = nlp_model(w).similarity(word_doc)\n"
     ]
    }
   ],
   "source": [
    "new_sentence = \"cat sit great mat\"\n",
    "tokens = new_sentence.split()\n",
    "\n",
    "sentence_vector = np.mean(\n",
    "    [get_vector_for_word(word, vocab, word_embeddings, nlp) for word in tokens],\n",
    "    axis=0\n",
    ")\n",
    "print(\"Sentence Vector with OOV Handling:\\n\", sentence_vector)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28fcae0",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "429fa814",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([embedding for embedding in df[\"sentence_embedding\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "4d224718",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"label\"].values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "082ba849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67         1\n",
      "           1       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.50         2\n",
      "   macro avg       0.25      0.50      0.33         2\n",
      "weighted avg       0.25      0.50      0.33         2\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aditisinha/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/aditisinha/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/aditisinha/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "X_train, X_test, y_train, y_test = train_test_split(x,y, test_size=0.20, random_state=2020)\n",
    "\n",
    "# Train Random Forest Classifier\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate model\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10aede0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4da308c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e29e86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5026c704",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f6d5c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d629ee2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d3aea7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293a5df9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d1838c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24b2008",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e560109",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2966caf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc663c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab9e203",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a262059e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7f2055",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef70552",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fabcd2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657ce4df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8441f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3105a426",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800be601",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511d2aa1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f23b4e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225c2183",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7b8e35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b4152d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b095f817",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac04971",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a224f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76f6964",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f2d274",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8873b674",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f8e664",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2dc2d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abcb174",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8817c3b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33e9a78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a326ef1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c875759",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2606fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793cbfa7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab2c7d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255f2512",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8d0fda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad0da46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6dd836",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30580504",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86a2b68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3994a9c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a2800f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311f9bcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4a707a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1adde2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879a6ab9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2616e9af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f17946",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70968dcc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5be024e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bcbaa84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff425b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb64341",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f1e07c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6fdbba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ae0c89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580e894b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aceefc52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef2bf92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff707332",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c460aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a745fcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb752965",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5a1c83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2153344f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f2af1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a42123",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852cd82a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c77059",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb630ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70d9f31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19b4bfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea18f6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e6aea6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52102317",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abacf398",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c7f090",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00fbb9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99023b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2904f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2199a962",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62703ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb0c980",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67022d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a477f88f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67981904",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7964e6d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e278ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f91dec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8ab430",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b6505c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24cce1dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ddb2151",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723b9827",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021a9051",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715559af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e32bf34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b183803",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9526b50e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e45d86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7807dbe7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4acebb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed564722",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c87a455",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da15b9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573bdf56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ee7554",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ff4e22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17fce5d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836fa831",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148f9c3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6c5f84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f78bf7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a2448f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd2e9dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0caf08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782dd9e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff39974",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e43fe60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6864f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e02525",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4f1b13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f053a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf0b1c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9cede03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb232c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2563f142",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7040507",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563a50f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911c4ab2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009cf774",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64cdca45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9cef6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f28582",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1539b9b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65964dfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaadd209",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5e5c44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f4c0d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2effe1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154b0088",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaee559e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebc3c99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd5edcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f98f1c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bcb6a3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb763de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c19e67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b821a77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a05a909",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5678c51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03cd992",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1faf3043",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4e81db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32bc91a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0503693e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e1c76e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f4a490",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96b7ed9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61314407",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a111de67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792e4c43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3f03c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969e2e07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b05e76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c2cf9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861c5625",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4239977",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bde3c14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c0e6ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cdc2009",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59416f94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbe1d23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1929c30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72a4a9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4eb1ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccdfdd35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8752e8cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ec655d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e145f7ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b1bdcc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b081932",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c57f71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c69b76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d399e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbdc9b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e844361d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d68545",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9877f2c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7696808b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820094be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b30e1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8def3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bcfa405",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea10939c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ead7f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c136a1b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a44ebc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90200b02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22df4e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf38835",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5add59b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a36228f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535011d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d605b290",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bde837",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80765765",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c3ba85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06bcf1ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eddc8ad7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da7ecbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3c2b5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a38fcc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce6c767",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf394d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1be1adf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1967ce31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17adb5b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf0b50f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f6729b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fcb977",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283f8f24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3bdf89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be0a592",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8be375c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ceff0b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9aeeba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0539647a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbca8fa5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8f1420",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2425f071",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f842e4ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54fbd03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86c581a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b038a0c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86714491",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd677cb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430690b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11df9462",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13863cee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ade608",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c042c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43a2096",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c370b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d865820",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a073b0e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec88ac1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4a5ddf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec6de2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ff3d11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1821161b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5cc28a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600a9703",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b44f0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3470574",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0626308",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca951d35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d161b0ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832522eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbf7356",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37902563",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4c872c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344d0221",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9fa907",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5c5e84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b95606",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c200359",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d424134",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48cc395d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385df4b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f961b05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ba0692",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b8256d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00787257",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f32486",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f063ab77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be350f06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3dc3640",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01331b95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67291783",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a808cdcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920e9ecb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eca9862",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ca560a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455d7d52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a64ba6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b76f73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f4fdf1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84443848",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ec62c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cefecaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7545540c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1cc252",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d682d368",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb89113",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd50dcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527966d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98eb933",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1235bd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a835050",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5114bf08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0af7f8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7266aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05012e02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8873a495",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01520fd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5654f87e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f5372d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092dcac0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98936b6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c46890f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d796cbdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6186f60f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5d9ac5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484e1811",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5acd53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b517388",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af9b17f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4e9b07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a144d43e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487b85fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4365cbd9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
